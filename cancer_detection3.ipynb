{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator,load_img,img_to_array\n",
    "from sklearn.datasets import load_files\n",
    "from keras.utils import to_categorical\n",
    "import cv2\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'data/train'\n",
    "valid_path = 'data/valid'\n",
    "test_path = 'data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading images for paths\n",
    "def load_images(path):\n",
    "    i = load_files(path)\n",
    "    return i['filenames'],i['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images,train_targets = load_images(train_path)\n",
    "valid_images,valid_targets = load_images(valid_path)\n",
    "test_images,test_targets = load_images(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting raw images to tensors\n",
    "def split(raw_image):\n",
    "    img = tf.contrib.keras.preprocessing.image.load_img(raw_image)\n",
    "    img = tf.contrib.keras.preprocessing.image.img_to_array(img)\n",
    "    img = cv2.resize(img,(256,256))/255.\n",
    "    return img\n",
    "def image_to_tensors(raw_images):\n",
    "    a = list()\n",
    "    for i in range(len(raw_images)):\n",
    "        img = split(raw_images[i])\n",
    "        a.append(img)\n",
    "    a = np.array(a)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensors = image_to_tensors(train_images)\n",
    "valid_tensors = image_to_tensors(valid_images)\n",
    "test_tensors = image_to_tensors(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(targets):\n",
    "    targets = to_categorical(targets)\n",
    "    return targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets = one_hot(train_targets)\n",
    "valid_targets = one_hot(valid_targets)\n",
    "test_targets = one_hot(test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nweights = {\\n    'wc1': tf.Variable(tf.random_uniform([3,3,3,16],minval=0.25,maxval=0.75)),\\n    'wc2': tf.Variable(tf.random_uniform([3,3,16,32],minval=0.25,maxval=0.75)),\\n    'wc3': tf.Variable(tf.random_uniform([3,3,32,64],minval=0.25,maxval=0.75)),\\n    'wc4': tf.Variable(tf.random_uniform([3,3,64,128],minval=0.25,maxval=0.75)),\\n    'wc5': tf.Variable(tf.random_uniform([3,3,128,256],minval=0.25,maxval=0.75)),\\n    'fc1': tf.Variable(tf.random_uniform([16*16*256,1024],minval=0.25,maxval=0.75)),\\n    'fc2': tf.Variable(tf.random_uniform([1024,3],minval=0.25,maxval=0.75))\\n}\\nbiases = {\\n    'bc1': tf.Variable(tf.random_uniform([16],minval=0.25,maxval=0.75)),\\n    'bc2': tf.Variable(tf.random_uniform([32],minval=0.25,maxval=0.75)),\\n    'bc3': tf.Variable(tf.random_uniform([64],minval=0.25,maxval=0.75)),\\n    'bc4': tf.Variable(tf.random_uniform([128],minval=0.25,maxval=0.75)),\\n    'bc5': tf.Variable(tf.random_uniform([256],minval=0.25,maxval=0.75)),\\n    'bf1': tf.Variable(tf.random_uniform([1024],minval=0.25,maxval=0.75)),\\n    'bf2': tf.Variable(tf.random_uniform([3],minval=0.25,maxval=0.75))\\n}\\n\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_filters(kernel_size,in_depth,out_depth):\n",
    "    return tf.Variable(tf.random_uniform([kernel_size,kernel_size,in_depth,out_depth],minval=0.25,maxval=0.75))\n",
    "def generate_biases(out_depth):\n",
    "    return tf.Variable(tf.random_uniform([out_depth],minval=0.25,maxval=0.75))\n",
    "def generate_weights_for_fc(in_nodes,out_nodes):\n",
    "    return tf.Variable(tf.random_uniform([in_nodes,out_nodes],minval=0.25,maxval=0.75))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "epochs = 50\n",
    "batch_size = 100\n",
    "dropout = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conv2d(image_batch,in_depth,out_depth):\n",
    "    kernel_size = 3\n",
    "    layer = tf.nn.conv2d(input=image_batch,filter=generate_filters(kernel_size,in_depth,out_depth),strides=[1,1,1,1],padding='SAME')\n",
    "    layer = tf.nn.bias_add(value=layer,bias=generate_biases(out_depth))\n",
    "    layer = tf.nn.relu(layer)\n",
    "    return layer\n",
    "def create_maxpool(conv_layer):\n",
    "    layer = tf.nn.max_pool(conv_layer,[1,3,3,1],[1,2,2,1],padding='SAME')\n",
    "    return layer\n",
    "def create_fc_after_conv(conv_layer,in_nodes,out_nodes,keep_prob):\n",
    "    layer = tf.reshape(conv_layer,[-1,16*16*256])\n",
    "    layer = tf.add(tf.matmul(layer,generate_weights_for_fc(in_nodes,out_nodes)),generate_biases(out_nodes))\n",
    "    layer = tf.nn.relu(layer)\n",
    "    layer = tf.nn.dropout(layer,keep_prob)\n",
    "    return layer\n",
    "def create_fc_after_fc(fc,in_nodes,out_nodes,keep_prob):\n",
    "    layer = tf.add(tf.matmul(fc,generate_weights_for_fc(in_nodes,out_nodes)),generate_biases(out_nodes))\n",
    "    layer = tf.nn.relu(layer)\n",
    "    layer = tf.nn.dropout(layer,keep_prob)\n",
    "    return layer\n",
    "def next_batch(image_batch,train_targets,batch,batch_size):\n",
    "    start = batch*batch_size\n",
    "    end = start + batch_size\n",
    "    min_train_batch = image_batch[start:end]\n",
    "    min_targets_batch = train_targets[start:end]\n",
    "    train_datagen = ImageDataGenerator(rotation_range=60,width_shift_range=0.1,height_shift_range=0.1,horizontal_flip=True,\n",
    "                                  shear_range=20,zoom_range=[0.2,0.2])\n",
    "    train_datagen.fit(x=min_train_batch,augment=True,rounds=2)\n",
    "    t = 0\n",
    "    for x_batch,y_batch in train_datagen.flow(min_train_batch,min_targets_batch,batch_size=batch_size):\n",
    "        t += 1\n",
    "        if t > 1:\n",
    "            break\n",
    "        return x_batch,y_batch\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convnet(x,keep_prob):\n",
    "    conv1 = create_conv2d(x,3,16)\n",
    "    max1 = create_maxpool(conv1)\n",
    "    conv2 = create_conv2d(max1,16,32)\n",
    "    max2 = create_maxpool(conv2)\n",
    "    conv3 = create_conv2d(max2,32,64)\n",
    "    max3 = create_maxpool(conv3)\n",
    "    conv4 = create_conv2d(max3,64,128)\n",
    "    max4 = create_maxpool(conv4)\n",
    "    conv5 = create_conv2d(max4,128,256)\n",
    "    fc1 = create_fc_after_conv(conv5,16*16*256,1024,dropout)\n",
    "    fc2 = create_fc_after_fc(fc1,1024,2048,dropout)\n",
    "    fc3 = tf.add(tf.matmul(fc2,generate_weights_for_fc(2048,3)),generate_biases(3))\n",
    "    fc3 = tf.nn.softmax(fc3)\n",
    "    return fc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch  1,loss 1.3914446830749512,Validation_accuracy0.2866666615009308\n",
      "Epoch  1, Batch  2,loss 1.3614447116851807,Validation_accuracy0.273333340883255\n",
      "Epoch  1, Batch  3,loss 1.4114446640014648,Validation_accuracy0.2666666805744171\n",
      "Epoch  1, Batch  4,loss 1.4514447450637817,Validation_accuracy0.2933333218097687\n",
      "Epoch  1, Batch  5,loss 1.4714447259902954,Validation_accuracy0.2666666805744171\n",
      "Epoch  1, Batch  6,loss 1.3714447021484375,Validation_accuracy0.2866666615009308\n",
      "Epoch  1, Batch  7,loss 1.3714447021484375,Validation_accuracy0.2866666615009308\n",
      "Epoch  1, Batch  8,loss 1.441444754600525,Validation_accuracy0.2866666615009308\n",
      "Epoch  1, Batch  9,loss 1.2914446592330933,Validation_accuracy0.30000001192092896\n",
      "Epoch  1, Batch 10,loss 1.441444754600525,Validation_accuracy0.2666666805744171\n",
      "Epoch  1, Batch 11,loss 1.3814446926116943,Validation_accuracy0.2800000011920929\n",
      "Epoch  1, Batch 12,loss 1.4214446544647217,Validation_accuracy0.273333340883255\n",
      "Epoch  1, Batch 13,loss 1.3614447116851807,Validation_accuracy0.2933333218097687\n",
      "Epoch  1, Batch 14,loss 1.401444673538208,Validation_accuracy0.2866666615009308\n",
      "Epoch  1, Batch 15,loss 1.4714447259902954,Validation_accuracy0.2866666615009308\n",
      "Epoch  1, Batch 16,loss 1.3814446926116943,Validation_accuracy0.2800000011920929\n",
      "Epoch  1, Batch 17,loss 1.441444754600525,Validation_accuracy0.2800000011920929\n",
      "Epoch  1, Batch 18,loss 1.401444673538208,Validation_accuracy0.2866666615009308\n",
      "Epoch  1, Batch 19,loss 1.441444754600525,Validation_accuracy0.30000001192092896\n",
      "Epoch  1, Batch 20,loss 1.4314446449279785,Validation_accuracy0.2800000011920929\n",
      "Epoch  2, Batch  1,loss 1.3714447021484375,Validation_accuracy0.2866666615009308\n",
      "Epoch  2, Batch  2,loss 1.3814446926116943,Validation_accuracy0.3199999928474426\n",
      "Epoch  2, Batch  3,loss 1.4114446640014648,Validation_accuracy0.2666666805744171\n",
      "Epoch  2, Batch  4,loss 1.441444754600525,Validation_accuracy0.3266666531562805\n",
      "Epoch  2, Batch  5,loss 1.4514447450637817,Validation_accuracy0.2800000011920929\n",
      "Epoch  2, Batch  6,loss 1.3814446926116943,Validation_accuracy0.2933333218097687\n",
      "Epoch  2, Batch  7,loss 1.3614447116851807,Validation_accuracy0.2933333218097687\n",
      "Epoch  2, Batch  8,loss 1.4214446544647217,Validation_accuracy0.30000001192092896\n",
      "Epoch  2, Batch  9,loss 1.3214447498321533,Validation_accuracy0.273333340883255\n",
      "Epoch  2, Batch 10,loss 1.4214446544647217,Validation_accuracy0.2933333218097687\n",
      "Epoch  2, Batch 11,loss 1.4114446640014648,Validation_accuracy0.2866666615009308\n",
      "Epoch  2, Batch 12,loss 1.4214446544647217,Validation_accuracy0.2866666615009308\n",
      "Epoch  2, Batch 13,loss 1.3714447021484375,Validation_accuracy0.2866666615009308\n",
      "Epoch  2, Batch 14,loss 1.3914446830749512,Validation_accuracy0.2866666615009308\n",
      "Epoch  2, Batch 15,loss 1.4614447355270386,Validation_accuracy0.2866666615009308\n",
      "Epoch  2, Batch 16,loss 1.3914446830749512,Validation_accuracy0.2666666805744171\n",
      "Epoch  2, Batch 17,loss 1.4314446449279785,Validation_accuracy0.2933333218097687\n",
      "Epoch  2, Batch 18,loss 1.4114446640014648,Validation_accuracy0.2933333218097687\n",
      "Epoch  2, Batch 19,loss 1.4714447259902954,Validation_accuracy0.273333340883255\n",
      "Epoch  2, Batch 20,loss 1.4514447450637817,Validation_accuracy0.2933333218097687\n",
      "Epoch  3, Batch  1,loss 1.4114446640014648,Validation_accuracy0.2933333218097687\n",
      "Epoch  3, Batch  2,loss 1.3914446830749512,Validation_accuracy0.2800000011920929\n",
      "Epoch  3, Batch  3,loss 1.4314446449279785,Validation_accuracy0.2800000011920929\n",
      "Epoch  3, Batch  4,loss 1.4814447164535522,Validation_accuracy0.2800000011920929\n",
      "Epoch  3, Batch  5,loss 1.4614447355270386,Validation_accuracy0.2866666615009308\n",
      "Epoch  3, Batch  6,loss 1.4214446544647217,Validation_accuracy0.31333333253860474\n",
      "Epoch  3, Batch  7,loss 1.3614447116851807,Validation_accuracy0.30666667222976685\n",
      "Epoch  3, Batch  8,loss 1.4214446544647217,Validation_accuracy0.30000001192092896\n",
      "Epoch  3, Batch  9,loss 1.2914446592330933,Validation_accuracy0.2800000011920929\n",
      "Epoch  3, Batch 10,loss 1.441444754600525,Validation_accuracy0.30000001192092896\n",
      "Epoch  3, Batch 11,loss 1.4314446449279785,Validation_accuracy0.2866666615009308\n",
      "Epoch  3, Batch 12,loss 1.441444754600525,Validation_accuracy0.2866666615009308\n",
      "Epoch  3, Batch 13,loss 1.3714447021484375,Validation_accuracy0.31333333253860474\n",
      "Epoch  3, Batch 14,loss 1.3514447212219238,Validation_accuracy0.2866666615009308\n",
      "Epoch  3, Batch 15,loss 1.4514447450637817,Validation_accuracy0.2866666615009308\n",
      "Epoch  3, Batch 16,loss 1.3914446830749512,Validation_accuracy0.2800000011920929\n",
      "Epoch  3, Batch 17,loss 1.441444754600525,Validation_accuracy0.2866666615009308\n",
      "Epoch  3, Batch 18,loss 1.4214446544647217,Validation_accuracy0.30000001192092896\n",
      "Epoch  3, Batch 19,loss 1.4814447164535522,Validation_accuracy0.2866666615009308\n",
      "Epoch  3, Batch 20,loss 1.4214446544647217,Validation_accuracy0.2800000011920929\n",
      "Epoch  4, Batch  1,loss 1.3814446926116943,Validation_accuracy0.2800000011920929\n",
      "Epoch  4, Batch  2,loss 1.3814446926116943,Validation_accuracy0.273333340883255\n",
      "Epoch  4, Batch  3,loss 1.4514447450637817,Validation_accuracy0.2933333218097687\n",
      "Epoch  4, Batch  4,loss 1.4514447450637817,Validation_accuracy0.273333340883255\n",
      "Epoch  4, Batch  5,loss 1.441444754600525,Validation_accuracy0.2866666615009308\n",
      "Epoch  4, Batch  6,loss 1.401444673538208,Validation_accuracy0.31333333253860474\n",
      "Epoch  4, Batch  7,loss 1.3314447402954102,Validation_accuracy0.2866666615009308\n",
      "Epoch  4, Batch  8,loss 1.441444754600525,Validation_accuracy0.2933333218097687\n",
      "Epoch  4, Batch  9,loss 1.3314447402954102,Validation_accuracy0.2866666615009308\n",
      "Epoch  4, Batch 10,loss 1.441444754600525,Validation_accuracy0.2866666615009308\n",
      "Epoch  4, Batch 11,loss 1.3614447116851807,Validation_accuracy0.2866666615009308\n",
      "Epoch  4, Batch 12,loss 1.4314446449279785,Validation_accuracy0.2666666805744171\n",
      "Epoch  4, Batch 13,loss 1.3514447212219238,Validation_accuracy0.2866666615009308\n",
      "Epoch  4, Batch 14,loss 1.401444673538208,Validation_accuracy0.30666667222976685\n",
      "Epoch  4, Batch 15,loss 1.4214446544647217,Validation_accuracy0.30666667222976685\n",
      "Epoch  4, Batch 16,loss 1.4314446449279785,Validation_accuracy0.2933333218097687\n",
      "Epoch  4, Batch 17,loss 1.4314446449279785,Validation_accuracy0.2666666805744171\n",
      "Epoch  4, Batch 18,loss 1.4114446640014648,Validation_accuracy0.2933333218097687\n",
      "Epoch  4, Batch 19,loss 1.4714447259902954,Validation_accuracy0.2666666805744171\n",
      "Epoch  4, Batch 20,loss 1.4114446640014648,Validation_accuracy0.30666667222976685\n",
      "Epoch  5, Batch  1,loss 1.4114446640014648,Validation_accuracy0.2866666615009308\n",
      "Epoch  5, Batch  2,loss 1.401444673538208,Validation_accuracy0.30000001192092896\n",
      "Epoch  5, Batch  3,loss 1.4214446544647217,Validation_accuracy0.2800000011920929\n",
      "Epoch  5, Batch  4,loss 1.4514447450637817,Validation_accuracy0.2933333218097687\n",
      "Epoch  5, Batch  5,loss 1.4214446544647217,Validation_accuracy0.2800000011920929\n",
      "Epoch  5, Batch  6,loss 1.401444673538208,Validation_accuracy0.2866666615009308\n",
      "Epoch  5, Batch  7,loss 1.3514447212219238,Validation_accuracy0.2800000011920929\n",
      "Epoch  5, Batch  8,loss 1.4514447450637817,Validation_accuracy0.2866666615009308\n",
      "Epoch  5, Batch  9,loss 1.2914446592330933,Validation_accuracy0.25999999046325684\n",
      "Epoch  5, Batch 10,loss 1.4514447450637817,Validation_accuracy0.2800000011920929\n",
      "Epoch  5, Batch 11,loss 1.3914446830749512,Validation_accuracy0.273333340883255\n",
      "Epoch  5, Batch 12,loss 1.4314446449279785,Validation_accuracy0.273333340883255\n",
      "Epoch  5, Batch 13,loss 1.3614447116851807,Validation_accuracy0.2866666615009308\n",
      "Epoch  5, Batch 14,loss 1.3814446926116943,Validation_accuracy0.2666666805744171\n",
      "Epoch  5, Batch 15,loss 1.4614447355270386,Validation_accuracy0.2800000011920929\n",
      "Epoch  5, Batch 16,loss 1.4114446640014648,Validation_accuracy0.2800000011920929\n",
      "Epoch  5, Batch 17,loss 1.4214446544647217,Validation_accuracy0.31333333253860474\n",
      "Epoch  5, Batch 18,loss 1.4214446544647217,Validation_accuracy0.2933333218097687\n",
      "Epoch  5, Batch 19,loss 1.4614447355270386,Validation_accuracy0.2800000011920929\n",
      "Epoch  5, Batch 20,loss 1.4514447450637817,Validation_accuracy0.2866666615009308\n",
      "Epoch  6, Batch  1,loss 1.401444673538208,Validation_accuracy0.273333340883255\n",
      "Epoch  6, Batch  2,loss 1.3614447116851807,Validation_accuracy0.273333340883255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6, Batch  3,loss 1.4114446640014648,Validation_accuracy0.2800000011920929\n",
      "Epoch  6, Batch  4,loss 1.4314446449279785,Validation_accuracy0.2800000011920929\n",
      "Epoch  6, Batch  5,loss 1.4114446640014648,Validation_accuracy0.2933333218097687\n",
      "Epoch  6, Batch  6,loss 1.401444673538208,Validation_accuracy0.2866666615009308\n",
      "Epoch  6, Batch  7,loss 1.3814446926116943,Validation_accuracy0.2933333218097687\n",
      "Epoch  6, Batch  8,loss 1.441444754600525,Validation_accuracy0.2933333218097687\n",
      "Epoch  6, Batch  9,loss 1.3114447593688965,Validation_accuracy0.2866666615009308\n",
      "Epoch  6, Batch 10,loss 1.4214446544647217,Validation_accuracy0.273333340883255\n",
      "Epoch  6, Batch 11,loss 1.4214446544647217,Validation_accuracy0.30000001192092896\n",
      "Epoch  6, Batch 12,loss 1.4514447450637817,Validation_accuracy0.2866666615009308\n",
      "Epoch  6, Batch 13,loss 1.3514447212219238,Validation_accuracy0.2800000011920929\n",
      "Epoch  6, Batch 14,loss 1.3814446926116943,Validation_accuracy0.2866666615009308\n",
      "Epoch  6, Batch 15,loss 1.441444754600525,Validation_accuracy0.2866666615009308\n",
      "Epoch  6, Batch 16,loss 1.401444673538208,Validation_accuracy0.2800000011920929\n",
      "Epoch  6, Batch 17,loss 1.441444754600525,Validation_accuracy0.25333333015441895\n",
      "Epoch  6, Batch 18,loss 1.4314446449279785,Validation_accuracy0.2800000011920929\n",
      "Epoch  6, Batch 19,loss 1.4814447164535522,Validation_accuracy0.31333333253860474\n",
      "Epoch  6, Batch 20,loss 1.441444754600525,Validation_accuracy0.2933333218097687\n",
      "Epoch  7, Batch  1,loss 1.3914446830749512,Validation_accuracy0.2933333218097687\n",
      "Epoch  7, Batch  2,loss 1.3814446926116943,Validation_accuracy0.273333340883255\n",
      "Epoch  7, Batch  3,loss 1.4314446449279785,Validation_accuracy0.2933333218097687\n",
      "Epoch  7, Batch  4,loss 1.4514447450637817,Validation_accuracy0.2800000011920929\n",
      "Epoch  7, Batch  5,loss 1.441444754600525,Validation_accuracy0.2866666615009308\n",
      "Epoch  7, Batch  6,loss 1.4114446640014648,Validation_accuracy0.2866666615009308\n",
      "Epoch  7, Batch  7,loss 1.3214447498321533,Validation_accuracy0.30666667222976685\n",
      "Epoch  7, Batch  8,loss 1.4114446640014648,Validation_accuracy0.2866666615009308\n",
      "Epoch  7, Batch  9,loss 1.2914446592330933,Validation_accuracy0.2800000011920929\n",
      "Epoch  7, Batch 10,loss 1.4214446544647217,Validation_accuracy0.273333340883255\n",
      "Epoch  7, Batch 11,loss 1.401444673538208,Validation_accuracy0.2866666615009308\n",
      "Epoch  7, Batch 12,loss 1.441444754600525,Validation_accuracy0.273333340883255\n",
      "Epoch  7, Batch 13,loss 1.3814446926116943,Validation_accuracy0.30666667222976685\n",
      "Epoch  7, Batch 14,loss 1.401444673538208,Validation_accuracy0.30000001192092896\n",
      "Epoch  7, Batch 15,loss 1.4314446449279785,Validation_accuracy0.273333340883255\n",
      "Epoch  7, Batch 16,loss 1.401444673538208,Validation_accuracy0.2933333218097687\n",
      "Epoch  7, Batch 17,loss 1.4214446544647217,Validation_accuracy0.2933333218097687\n",
      "Epoch  7, Batch 18,loss 1.3914446830749512,Validation_accuracy0.2866666615009308\n",
      "Epoch  7, Batch 19,loss 1.441444754600525,Validation_accuracy0.273333340883255\n",
      "Epoch  7, Batch 20,loss 1.4314446449279785,Validation_accuracy0.2933333218097687\n",
      "Epoch  8, Batch  1,loss 1.3714447021484375,Validation_accuracy0.2866666615009308\n",
      "Epoch  8, Batch  2,loss 1.3914446830749512,Validation_accuracy0.2800000011920929\n",
      "Epoch  8, Batch  3,loss 1.441444754600525,Validation_accuracy0.30000001192092896\n",
      "Epoch  8, Batch  4,loss 1.4514447450637817,Validation_accuracy0.2866666615009308\n",
      "Epoch  8, Batch  5,loss 1.4114446640014648,Validation_accuracy0.2666666805744171\n",
      "Epoch  8, Batch  6,loss 1.4114446640014648,Validation_accuracy0.2800000011920929\n",
      "Epoch  8, Batch  7,loss 1.341444730758667,Validation_accuracy0.2866666615009308\n",
      "Epoch  8, Batch  8,loss 1.3914446830749512,Validation_accuracy0.30000001192092896\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32,[None,256,256,3])\n",
    "y = tf.placeholder(tf.float32,[None,3])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "logits = convnet(x,keep_prob)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(logits,1),tf.argmax(y,1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.allocator_type ='BFC'\n",
    "config.gpu_options.allow_growth = True\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(train_tensors.shape[0]//batch_size):\n",
    "            batch_x,batch_y = next_batch(train_tensors,train_targets,batch,batch_size)\n",
    "            #batch_y = next_batch(train_targets,batch_size)\n",
    "            \n",
    "            sess.run(optimizer,feed_dict={\n",
    "                x: batch_x,\n",
    "                y: batch_y,\n",
    "                keep_prob:dropout\n",
    "            })\n",
    "            loss = sess.run(cost,feed_dict={\n",
    "                x: batch_x,\n",
    "                y: batch_y,\n",
    "                keep_prob: 1.\n",
    "            })\n",
    "            valid_acc = sess.run(accuracy,feed_dict={\n",
    "                x:valid_tensors[:],\n",
    "                y:valid_targets[:],\n",
    "                keep_prob:1.\n",
    "            })\n",
    "            \n",
    "            print('Epoch {:>2}, Batch{:>3},loss {:>3},Validation_accuracy{:>3}'.format(epoch+1,batch+1,loss,valid_acc))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempted to use a closed Session.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-78a5858dff10>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtest_tensors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtest_targets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m })\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Testing accuracy {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Gowtham\\Anaconda3\\envs\\dog-project\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Gowtham\\Anaconda3\\envs\\dog-project\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1056\u001b[0m     \u001b[1;31m# Check session.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1057\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1058\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Attempted to use a closed Session.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1059\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Attempted to use a closed Session."
     ]
    }
   ],
   "source": [
    "test_acc = sess.run(accuracy,feed_dict={\n",
    "    x:test_tensors[:],\n",
    "    y:test_targets[:],\n",
    "    keep_prob:1.\n",
    "})\n",
    "print('Testing accuracy {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dog-project]",
   "language": "python",
   "name": "conda-env-dog-project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
